{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kosta\\anaconda3\\envs\\krenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Load the English NLP model from spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to convert natural language to a SPARQL query for DBpedia\n",
    "def convert_to_sparql_query(query_text):\n",
    "    # Perform natural language processing on the query\n",
    "    doc = nlp(query_text)\n",
    "\n",
    "    # Extract entities and relationships from the query\n",
    "    entities = [token.text for token in doc if token.ent_type_]\n",
    "    relationships = [token.text for token in doc if token.dep_ == \"ROOT\"]\n",
    "\n",
    "    # Build a SPARQL query template\n",
    "    sparql_query_template = \"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "        SELECT ?subject ?property ?object\n",
    "        WHERE {{\n",
    "            ?subject dbo:{entity} ?object.\n",
    "            OPTIONAL {{ ?object ?property ?value. }}\n",
    "        }}\n",
    "        LIMIT 1\n",
    "    \"\"\"\n",
    "\n",
    "    # Populate the template with the extracted entities\n",
    "    sparql_query = sparql_query_template.format(entity=entities[0])\n",
    "\n",
    "    return sparql_query\n",
    "\n",
    "# Function to execute the SPARQL query and return the result\n",
    "def execute_sparql_query(query):\n",
    "    # Set up the SPARQL endpoint for DBpedia\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    # Execute the query\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    return results['results']['bindings']\n",
    "\n",
    "# Example usage\n",
    "query_text = \"What is the capital of France?\"\n",
    "sparql_query = convert_to_sparql_query(query_text)\n",
    "query_result = execute_sparql_query(sparql_query)\n",
    "\n",
    "# Print the result\n",
    "for result in query_result:\n",
    "    subject = result['subject']['value'].split('/')[-1]\n",
    "    property_name = result.get('property', {}).get('value', '').split('/')[-1]\n",
    "    object_value = result['object']['value'].split('/')[-1]\n",
    "    print(f\"{subject} {property_name}: {object_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barack', 'Obama']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Load the English NLP model from spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to process a natural language query and return the results from DBpedia\n",
    "def query_dbpedia(query_text):\n",
    "    # Perform natural language processing on the query\n",
    "    doc = nlp(query_text)\n",
    "\n",
    "    # Extract entities from the query\n",
    "    entities = [token.text for token in doc if token.ent_type_]\n",
    "    print(entities)\n",
    "    # Build and execute the SPARQL query\n",
    "    sparql_query = f\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "    SELECT ?property ?value\n",
    "    WHERE {{\n",
    "        dbo:{entities[0]} ?property ?value.\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up the SPARQL endpoint for DBpedia\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    sparql.setQuery(sparql_query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    # Execute the query\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    # Return the results\n",
    "    return results['results']['bindings']\n",
    "\n",
    "# Example usage\n",
    "query_result = query_dbpedia(\"Tell me about Barack Obama.\")\n",
    "for result in query_result:\n",
    "    property_name = result['property']['value'].split('/')[-1]\n",
    "    value = result['value']['value']\n",
    "    print(f\"{property_name}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/mlearning-ai/semantic-search-via-knowledge-graphs-cc9da99dab4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_triplets(sentence):\n",
    "    doc = nlp(sentence)  # Parse the sentence with spaCy\n",
    "    triplets = []\n",
    "    for noun_chunk in doc.noun_chunks:  # Iterate over the noun chunks in the sentence\n",
    "        # Extract the text of the noun chunk and use it as the subject of the triplet\n",
    "        subject = noun_chunk.text\n",
    "        # Find the verb that governs the noun chunk and use it as the predicate of the triplet\n",
    "        for token in noun_chunk.root.children:\n",
    "            if token.dep_ == \"ROOT\":\n",
    "                predicate = token.text\n",
    "                print(predicate)\n",
    "        # Find the direct object of the verb and use it as the object of the triplet\n",
    "        for token in noun_chunk.root.children:\n",
    "            if token.dep_ == \"dobj\":\n",
    "                object = token.text\n",
    "                print(object)\n",
    "        triplets.append((subject, predicate, object))\n",
    "    return triplets\n",
    "\n",
    "# Define a sentence to parse\n",
    "sentence = \"Music bands based in Jönköping\"\n",
    "doc = nlp(sentence)\n",
    "\n",
    "for token in noun_chunk.root.children:\n",
    "    print(token.text)\n",
    "# for tok in doc:\n",
    "#   print(tok.text, \"...\", tok.dep_)\n",
    "# Extract the triplets from the sentence\n",
    "# triplets = extract_triplets(sentence)\n",
    "\n",
    "# # Print the triplets\n",
    "# for triplet in triplets:\n",
    "#     print(triplet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     22\u001b[0m natural_language_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList books written by George Orwell.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 23\u001b[0m sparql_query \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sparql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnatural_language_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNatural Language Input:\u001b[39m\u001b[38;5;124m\"\u001b[39m, natural_language_input)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated SPARQL Query:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sparql_query)\n",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m, in \u001b[0;36mgenerate_sparql_query\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_sparql_query\u001b[39m(prompt):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Make a request to the ChatGPT API for generating SPARQL queries\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-davinci-003\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Extract the generated SPARQL query from the API response\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     generated_query \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\kosta\\anaconda3\\envs\\krenv\\Lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\kosta\\anaconda3\\envs\\krenv\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\kosta\\anaconda3\\envs\\krenv\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\kosta\\anaconda3\\envs\\krenv\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kosta\\anaconda3\\envs\\krenv\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "def generate_sparql_query(prompt):\n",
    "    # Make a request to the ChatGPT API for generating SPARQL queries\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=0.7,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    # Extract the generated SPARQL query from the API response\n",
    "    generated_query = response['choices'][0]['text'].strip()\n",
    "\n",
    "    return generated_query\n",
    "\n",
    "# Example usage\n",
    "natural_language_input = \"List books written by George Orwell.\"\n",
    "sparql_query = generate_sparql_query(natural_language_input)\n",
    "\n",
    "print(\"Natural Language Input:\", natural_language_input)\n",
    "print(\"Generated SPARQL Query:\", sparql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing SPARQL query: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b\"Virtuoso 37000 Error SP030: SPARQL compiler, line 5: Undefined namespace prefix in prefix:localpart notation at 'dbpedia:DBpedia' before '?property'\\n\\nSPARQL query:\\n#output-format:application/sparql-results+json\\n\\n                SELECT ?property ?value\\n                WHERE {\\n                    dbpedia:DBpedia ?property ?value.\\n                }\\n            \\n\"\n",
      "No results.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Set up the question-answering pipeline using a pre-trained model\n",
    "nlp_qa = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n",
    "\n",
    "def convert_question_to_query(question):\n",
    "    try:\n",
    "        # Use the question-answering model to get an answer\n",
    "        answer = nlp_qa(question=question, context=\"DBpedia is a large multi-domain ontology...\")\n",
    "\n",
    "        # Extract the answer and construct a simple SPARQL query\n",
    "        if answer['answer']:\n",
    "            entity_name = answer['answer']\n",
    "            query_string = f\"\"\"\n",
    "                SELECT ?property ?value\n",
    "                WHERE {{\n",
    "                    dbpedia:{entity_name} ?property ?value.\n",
    "                }}\n",
    "            \"\"\"\n",
    "\n",
    "            return query_string\n",
    "        else:\n",
    "            print(\"Unable to extract entity from the question.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def execute_query(query):\n",
    "    try:\n",
    "        # Set the DBpedia endpoint URL\n",
    "        sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "        # Set the query string\n",
    "        sparql.setQuery(query)\n",
    "\n",
    "        # Set the return format to JSON\n",
    "        sparql.setReturnFormat(JSON)\n",
    "\n",
    "        # Execute the query and parse the results\n",
    "        results = sparql.query().convert()\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SPARQL query: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "question = \"What is the capital of Germany?\"\n",
    "query = convert_question_to_query(question)\n",
    "\n",
    "if query:\n",
    "    results = execute_query(query)\n",
    "    if results:\n",
    "        # Process and print the query results\n",
    "        for result in results[\"results\"][\"bindings\"]:\n",
    "            for var in result:\n",
    "                print(f\"{var}: {result[var]['value']}\")\n",
    "    else:\n",
    "        print(\"No results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Query: List all the songs of Beatles.\n",
      "SPARQL Query: SPARQL: Liste alle Lieder von Beatles.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "def generate_sparql(query, model, tokenizer):\n",
    "    input_text = f\"translate English to SPARQL: {query}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    output = model.generate(input_ids)\n",
    "    sparql_query = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return sparql_query\n",
    "\n",
    "# Load pre-trained T5 model and tokenizer\n",
    "model_name = \"t5-base\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Example natural language query\n",
    "natural_language_query = \"List all the songs of Beatles.\"\n",
    "\n",
    "# Generate SPARQL query\n",
    "sparql_query = generate_sparql(natural_language_query, model, tokenizer)\n",
    "\n",
    "# Print the result\n",
    "print(\"Natural Language Query:\", natural_language_query)\n",
    "print(\"SPARQL Query:\", sparql_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
