{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kosta\\anaconda3\\envs\\krenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Load the English NLP model from spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to convert natural language to a SPARQL query for DBpedia\n",
    "def convert_to_sparql_query(query_text):\n",
    "    # Perform natural language processing on the query\n",
    "    doc = nlp(query_text)\n",
    "\n",
    "    # Extract entities and relationships from the query\n",
    "    entities = [token.text for token in doc if token.ent_type_]\n",
    "    relationships = [token.text for token in doc if token.dep_ == \"ROOT\"]\n",
    "\n",
    "    # Build a SPARQL query template\n",
    "    sparql_query_template = \"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "        SELECT ?subject ?property ?object\n",
    "        WHERE {{\n",
    "            ?subject dbo:{entity} ?object.\n",
    "            OPTIONAL {{ ?object ?property ?value. }}\n",
    "        }}\n",
    "        LIMIT 1\n",
    "    \"\"\"\n",
    "\n",
    "    # Populate the template with the extracted entities\n",
    "    sparql_query = sparql_query_template.format(entity=entities[0])\n",
    "\n",
    "    return sparql_query\n",
    "\n",
    "# Function to execute the SPARQL query and return the result\n",
    "def execute_sparql_query(query):\n",
    "    # Set up the SPARQL endpoint for DBpedia\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    # Execute the query\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    return results['results']['bindings']\n",
    "\n",
    "# Example usage\n",
    "query_text = \"What is the capital of France?\"\n",
    "sparql_query = convert_to_sparql_query(query_text)\n",
    "query_result = execute_sparql_query(sparql_query)\n",
    "\n",
    "# Print the result\n",
    "for result in query_result:\n",
    "    subject = result['subject']['value'].split('/')[-1]\n",
    "    property_name = result.get('property', {}).get('value', '').split('/')[-1]\n",
    "    object_value = result['object']['value'].split('/')[-1]\n",
    "    print(f\"{subject} {property_name}: {object_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barack', 'Obama']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Load the English NLP model from spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to process a natural language query and return the results from DBpedia\n",
    "def query_dbpedia(query_text):\n",
    "    # Perform natural language processing on the query\n",
    "    doc = nlp(query_text)\n",
    "\n",
    "    # Extract entities from the query\n",
    "    entities = [token.text for token in doc if token.ent_type_]\n",
    "    print(entities)\n",
    "    # Build and execute the SPARQL query\n",
    "    sparql_query = f\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "    SELECT ?property ?value\n",
    "    WHERE {{\n",
    "        dbo:{entities[0]} ?property ?value.\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up the SPARQL endpoint for DBpedia\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    sparql.setQuery(sparql_query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    # Execute the query\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    # Return the results\n",
    "    return results['results']['bindings']\n",
    "\n",
    "# Example usage\n",
    "query_result = query_dbpedia(\"Tell me about Barack Obama.\")\n",
    "for result in query_result:\n",
    "    property_name = result['property']['value'].split('/')[-1]\n",
    "    value = result['value']['value']\n",
    "    print(f\"{property_name}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/mlearning-ai/semantic-search-via-knowledge-graphs-cc9da99dab4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_triplets(sentence):\n",
    "    doc = nlp(sentence)  # Parse the sentence with spaCy\n",
    "    triplets = []\n",
    "    for noun_chunk in doc.noun_chunks:  # Iterate over the noun chunks in the sentence\n",
    "        # Extract the text of the noun chunk and use it as the subject of the triplet\n",
    "        subject = noun_chunk.text\n",
    "        # Find the verb that governs the noun chunk and use it as the predicate of the triplet\n",
    "        for token in noun_chunk.root.children:\n",
    "            if token.dep_ == \"ROOT\":\n",
    "                predicate = token.text\n",
    "                print(predicate)\n",
    "        # Find the direct object of the verb and use it as the object of the triplet\n",
    "        for token in noun_chunk.root.children:\n",
    "            if token.dep_ == \"dobj\":\n",
    "                object = token.text\n",
    "                print(object)\n",
    "        triplets.append((subject, predicate, object))\n",
    "    return triplets\n",
    "\n",
    "# Define a sentence to parse\n",
    "sentence = \"Music bands based in Jönköping\"\n",
    "doc = nlp(sentence)\n",
    "\n",
    "for token in noun_chunk.root.children:\n",
    "    print(token.text)\n",
    "# for tok in doc:\n",
    "#   print(tok.text, \"...\", tok.dep_)\n",
    "# Extract the triplets from the sentence\n",
    "# triplets = extract_triplets(sentence)\n",
    "\n",
    "# # Print the triplets\n",
    "# for triplet in triplets:\n",
    "#     print(triplet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     22\u001b[0m natural_language_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList books written by George Orwell.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 23\u001b[0m sparql_query \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sparql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnatural_language_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNatural Language Input:\u001b[39m\u001b[38;5;124m\"\u001b[39m, natural_language_input)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated SPARQL Query:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sparql_query)\n",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m, in \u001b[0;36mgenerate_sparql_query\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_sparql_query\u001b[39m(prompt):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Make a request to the ChatGPT API for generating SPARQL queries\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-davinci-003\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Extract the generated SPARQL query from the API response\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     generated_query \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\kosta\\anaconda3\\envs\\krenv\\Lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "def generate_sparql_query(prompt):\n",
    "    # Make a request to the ChatGPT API for generating SPARQL queries\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "        temperature=0.7,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    # Extract the generated SPARQL query from the API response\n",
    "    generated_query = response['choices'][0]['text'].strip()\n",
    "\n",
    "    return generated_query\n",
    "\n",
    "# Example usage\n",
    "natural_language_input = \"List books written by George Orwell.\"\n",
    "sparql_query = generate_sparql_query(natural_language_input)\n",
    "\n",
    "print(\"Natural Language Input:\", natural_language_input)\n",
    "print(\"Generated SPARQL Query:\", sparql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing SPARQL query: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b\"Virtuoso 37000 Error SP030: SPARQL compiler, line 5: Undefined namespace prefix in prefix:localpart notation at 'dbpedia:DBpedia' before '?property'\\n\\nSPARQL query:\\n#output-format:application/sparql-results+json\\n\\n                SELECT ?property ?value\\n                WHERE {\\n                    dbpedia:DBpedia ?property ?value.\\n                }\\n            \\n\"\n",
      "No results.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Set up the question-answering pipeline using a pre-trained model\n",
    "nlp_qa = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n",
    "\n",
    "def convert_question_to_query(question):\n",
    "    try:\n",
    "        # Use the question-answering model to get an answer\n",
    "        answer = nlp_qa(question=question, context=\"DBpedia is a large multi-domain ontology...\")\n",
    "\n",
    "        # Extract the answer and construct a simple SPARQL query\n",
    "        if answer['answer']:\n",
    "            entity_name = answer['answer']\n",
    "            query_string = f\"\"\"\n",
    "                SELECT ?property ?value\n",
    "                WHERE {{\n",
    "                    dbpedia:{entity_name} ?property ?value.\n",
    "                }}\n",
    "            \"\"\"\n",
    "\n",
    "            return query_string\n",
    "        else:\n",
    "            print(\"Unable to extract entity from the question.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def execute_query(query):\n",
    "    try:\n",
    "        # Set the DBpedia endpoint URL\n",
    "        sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "        # Set the query string\n",
    "        sparql.setQuery(query)\n",
    "\n",
    "        # Set the return format to JSON\n",
    "        sparql.setReturnFormat(JSON)\n",
    "\n",
    "        # Execute the query and parse the results\n",
    "        results = sparql.query().convert()\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SPARQL query: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "question = \"What is the capital of Germany?\"\n",
    "query = convert_question_to_query(question)\n",
    "\n",
    "if query:\n",
    "    results = execute_query(query)\n",
    "    if results:\n",
    "        # Process and print the query results\n",
    "        for result in results[\"results\"][\"bindings\"]:\n",
    "            for var in result:\n",
    "                print(f\"{var}: {result[var]['value']}\")\n",
    "    else:\n",
    "        print(\"No results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Query: List all the songs of Beatles.\n",
      "SPARQL Query: SPARQL: Liste alle Lieder von Beatles.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "def generate_sparql(query, model, tokenizer):\n",
    "    input_text = f\"translate English to SPARQL: {query}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    output = model.generate(input_ids)\n",
    "    sparql_query = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return sparql_query\n",
    "\n",
    "# Load pre-trained T5 model and tokenizer\n",
    "model_name = \"t5-base\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Example natural language query\n",
    "natural_language_query = \"List all the songs of Beatles.\"\n",
    "\n",
    "# Generate SPARQL query\n",
    "sparql_query = generate_sparql(natural_language_query, model, tokenizer)\n",
    "\n",
    "# Print the result\n",
    "print(\"Natural Language Query:\", natural_language_query)\n",
    "print(\"SPARQL Query:\", sparql_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
