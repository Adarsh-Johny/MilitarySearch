{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Load the English NLP model from spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to convert natural language to a SPARQL query for DBpedia\n",
    "def convert_to_sparql_query(query_text):\n",
    "    # Perform natural language processing on the query\n",
    "    doc = nlp(query_text)\n",
    "\n",
    "    # Extract entities and relationships from the query\n",
    "    entities = [token.text for token in doc if token.ent_type_]\n",
    "    relationships = [token.text for token in doc if token.dep_ == \"ROOT\"]\n",
    "\n",
    "    # Build a SPARQL query template\n",
    "    sparql_query_template = \"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "        SELECT ?subject ?property ?object\n",
    "        WHERE {{\n",
    "            ?subject dbo:{entity} ?object.\n",
    "            OPTIONAL {{ ?object ?property ?value. }}\n",
    "        }}\n",
    "        LIMIT 1\n",
    "    \"\"\"\n",
    "\n",
    "    # Populate the template with the extracted entities\n",
    "    sparql_query = sparql_query_template.format(entity=entities[0])\n",
    "\n",
    "    return sparql_query\n",
    "\n",
    "# Function to execute the SPARQL query and return the result\n",
    "def execute_sparql_query(query):\n",
    "    # Set up the SPARQL endpoint for DBpedia\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    # Execute the query\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    return results['results']['bindings']\n",
    "\n",
    "# Example usage\n",
    "query_text = \"What is the capital of France?\"\n",
    "sparql_query = convert_to_sparql_query(query_text)\n",
    "query_result = execute_sparql_query(sparql_query)\n",
    "\n",
    "# Print the result\n",
    "for result in query_result:\n",
    "    subject = result['subject']['value'].split('/')[-1]\n",
    "    property_name = result.get('property', {}).get('value', '').split('/')[-1]\n",
    "    object_value = result['object']['value'].split('/')[-1]\n",
    "    print(f\"{subject} {property_name}: {object_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barack', 'Obama']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Load the English NLP model from spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to process a natural language query and return the results from DBpedia\n",
    "def query_dbpedia(query_text):\n",
    "    # Perform natural language processing on the query\n",
    "    doc = nlp(query_text)\n",
    "\n",
    "    # Extract entities from the query\n",
    "    entities = [token.text for token in doc if token.ent_type_]\n",
    "    print(entities)\n",
    "    # Build and execute the SPARQL query\n",
    "    sparql_query = f\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "    SELECT ?property ?value\n",
    "    WHERE {{\n",
    "        dbo:{entities[0]} ?property ?value.\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up the SPARQL endpoint for DBpedia\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    sparql.setQuery(sparql_query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    # Execute the query\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    # Return the results\n",
    "    return results['results']['bindings']\n",
    "\n",
    "# Example usage\n",
    "query_result = query_dbpedia(\"Tell me about Barack Obama.\")\n",
    "for result in query_result:\n",
    "    property_name = result['property']['value'].split('/')[-1]\n",
    "    value = result['value']['value']\n",
    "    print(f\"{property_name}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/mlearning-ai/semantic-search-via-knowledge-graphs-cc9da99dab4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_triplets(sentence):\n",
    "    doc = nlp(sentence)  # Parse the sentence with spaCy\n",
    "    triplets = []\n",
    "    for noun_chunk in doc.noun_chunks:  # Iterate over the noun chunks in the sentence\n",
    "        # Extract the text of the noun chunk and use it as the subject of the triplet\n",
    "        subject = noun_chunk.text\n",
    "        # Find the verb that governs the noun chunk and use it as the predicate of the triplet\n",
    "        for token in noun_chunk.root.children:\n",
    "            if token.dep_ == \"ROOT\":\n",
    "                predicate = token.text\n",
    "                print(predicate)\n",
    "        # Find the direct object of the verb and use it as the object of the triplet\n",
    "        for token in noun_chunk.root.children:\n",
    "            if token.dep_ == \"dobj\":\n",
    "                object = token.text\n",
    "                print(object)\n",
    "        triplets.append((subject, predicate, object))\n",
    "    return triplets\n",
    "\n",
    "# Define a sentence to parse\n",
    "sentence = \"Music bands based in Jönköping\"\n",
    "doc = nlp(sentence)\n",
    "\n",
    "for token in noun_chunk.root.children:\n",
    "    print(token.text)\n",
    "# for tok in doc:\n",
    "#   print(tok.text, \"...\", tok.dep_)\n",
    "# Extract the triplets from the sentence\n",
    "# triplets = extract_triplets(sentence)\n",
    "\n",
    "# # Print the triplets\n",
    "# for triplet in triplets:\n",
    "#     print(triplet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
